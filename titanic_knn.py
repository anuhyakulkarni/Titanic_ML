# -*- coding: utf-8 -*-
"""titanic_knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QzmGzgkJfaGJOgceFbM9LBDyPQBBAUn

#TITANIC :  LEARNING FROM DISASTER

The following dataset has been taken from kaggle. 
https://www.kaggle.com/c/titanic/data

Dataset description:The dataset has a set of 12 columns ,namely:passenger ID, passenger class, name, sex, age, sibsp,parch,ticket,fare,embarked and survived.Rest of the info will be follow as we go...

Importing the required libraries: Numpy(for mathematical calculations),Pandas(),Matplot lib(for graphs), OS(to upload the saved .csv),Seaborn(for visualisation tools)  and Sklearn( for training tools)
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import seaborn as sns
from sklearn.model_selection import train_test_split

from google.colab import files
files.upload()

titanic= pd.read_csv("train.csv") #Saving the csv file into a dataframe "titanic"

titanic.head()

"""After looking at the head and the desription, It is observed that the dataset has 12 columns :passengerId,name, ticket ,parch,cabin,sex,age
,SibSp( if the passenger has a sibling or a spouse),
embarked(the station where passengers embarked the ship :priceton,)
,Pclass(1,2,3)

survived column is the target

#we use seaborn tools for some visualisation of all data available
"""

#heatmap null for checking if the dataframe has any null values
sns.heatmap(titanic.isnull())

# The graph shows the probability of no of deaths to survival (death:survival::0:1)
sns.countplot(x='Survived',data=titanic)

#The graph shows the probability of no of deaths to survival of different passenger classes
sns.countplot(x='Survived',hue='Pclass',data=titanic)

#visualisation of all the features 
sns.pairplot(titanic,hue='Survived')

"""the features are compared using PEASON CORRELATION :"""

data2 = titanic.corr('pearson')
data2

#absolute value of correlation
 abs(data2.loc['Survived']).sort_values(ascending=False)

sns.distplot(titanic['Age'])

"""#dropping of null/insignificant features"""

titanic.drop('Cabin',axis=1,inplace=True)

Male=pd.get_dummies(titanic['Sex'],drop_first=True)

embark=pd.get_dummies(titanic['Embarked'],drop_first=True)

titanic.drop('Embarked',axis=1,inplace=True)

titanic=pd.concat([titanic,Male,embark],axis=1)

titanic.drop(['Name','Sex','Ticket','PassengerId'],axis=1,inplace=True)

titanic.drop(['Age'],axis=1,inplace=True)

titanic.dropna()

"""after dropping the values"""

X.head()

sns.heatmap(titanic.isnull())

"""SCALING THE DATA"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

scaler.fit(titanic.drop('Survived',axis=1))

scaled_features=scaler.transform(titanic.drop('Survived',axis=1))

df_feat=pd.DataFrame(scaled_features,columns=titanic.drop('Survived', axis=1).columns)

df_feat

"""#training model using KNN ALGORITHM"""

X=df_feat
Y=titanic['Survived']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)

from sklearn.neighbors import KNeighborsClassifier

"""from sklearn.neighbors import KNeigborsClassifier"""

knn=KNeighborsClassifier()

knn.fit(x_train,y_train)

pred=knn.predict(x_test)

from sklearn.metrics import confusion_matrix

from sklearn.metrics import classification_report

print(confusion_matrix(y_test,pred))

print(classification_report(y_test,pred))

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(pred,y_test)
accuracy